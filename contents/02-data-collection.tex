\section{Модуль 1: Сбор данных для подготовки датасета по сети Bitcoin}
В рамках первого модуля НИРС была поставлена задача по сбору данных для подготовки датасета, предназначенного для обучения классификатора криптовалютных транзакций. Основной целью являлось создание структурированного набора данных, содержащего информацию об адресах Bitcoin и связанных с ними транзакциях.

Классификация Bitcoin-адресов по типам кошельков является критически важной задачей в области анализа блокчейн-данных. Точная идентификация типов кошельков (биржи, майнеры, микшинг-сервисы, азартные игры) имеет практическое значение для регуляторного надзора, анализа рисков в криптовалютных операциях, исследования экономических паттернов в экосистеме Bitcoin и разработки инструментов для правоохранительных органов.

Проблема классификации Bitcoin-адресов приобретает особую актуальность в связи с ростом объемов криптовалютных транзакций (ежедневный объем Bitcoin превышает 300,000 операций), регуляторными требованиями соблюдения AML/KYC процедур, необходимостью выявления подозрительной активности и мошеннических схем, а также исследовательскими задачами понимания экономических паттернов в криптовалютной экосистеме.

\subsection{Источники данных и методология сбора}

\subsubsection{Базовый источник данных}

В качестве базового источника данных был использован датасет Гарвардского университета \cite{harvard_dataset}. Данный датасет содержит пары "адрес-категория" для Bitcoin-адресов, где каждая категория представляет собой тип сервиса или организации, связанной с адресом. Датасет включает категории: exchange (биржи криптовалют), gambling (азартные игры), miner (майнеры), services (различные сервисы) и coinjoin-like (адреса, связанные с технологиями повышения приватности).

Для получения актуальных данных о Bitcoin-адресах и транзакциях был разработан автоматизированный процесс сбора данных через API Bitcoin-эксплорера \cite{bitcoin_explorer_api}\cite{walletexplorer_api}. Данный подход основан на принципах работы Bitcoin-сети, описанных в оригинальной работе \cite{bitcoin_whitepaper}, и использует методы анализа блокчейна, разработанные в исследованиях \cite{blockchain_analysis_survey, bitcoin_privacy_analysis, bitcoin_clustering}.

\textbf{Характеристики базового датасета.}
Базовый набор включает более 8{,}000 Bitcoin-адресов с верифицированными метками классов и охватывает период с 2009 по 2020 годы. Разметка выполнена на основе экспертной оценки, что обеспечивает высокое качество категорий, а данные регулярно актуализируются по мере появления новых транзакций. Использованы проверенные источники и процедуры валидации категорий, что позволяет опираться на датасет как на достоверную основу для последующего анализа.

\subsubsection{Архитектура системы сбора данных}

Для получения актуальных данных о Bitcoin-адресах и транзакциях была разработана многоуровневая архитектура системы сбора данных, основанная на принципах модульности, устойчивости и производительности. Архитектура представляет собой совокупность взаимосвязанных компонентов, каждый из которых отвечает за определенный аспект процесса сбора и обработки данных.

\textbf{Основные компоненты архитектуры системы:}

\textbf{CollectorConfig} представляет собой централизованную систему конфигурации, которая обеспечивает единообразное управление параметрами всей системы. Данный компонент включает настройки URL API-эндпоинтов, временные параметры (задержки между запросами, таймауты), параметры параллельной обработки (количество воркеров, размеры батчей), а также настройки retry-логики и контроля скорости запросов. Централизация конфигурации позволяет легко адаптировать систему под различные условия работы и требования API-провайдеров.

\textbf{Модели данных (AddressData/TransactionData)} обеспечивают структурированное представление адресов и транзакций Bitcoin. Эти модели включают типизированные поля для всех атрибутов адресов и транзакций, поддержку JSON сериализации для сложных структур данных, встроенную валидацию данных на уровне модели, а также механизмы обеспечения целостности данных. Использование строго типизированных моделей исключает ошибки, связанные с неправильным форматом данных, и обеспечивает консистентность на протяжении всего процесса обработки.

\textbf{WalletExplorerAPI} представляет собой специализированный HTTP-клиент, разработанный для взаимодействия с API Bitcoin-эксплорера \cite{walletexplorer_api}. Клиент реализует продвинутую retry-стратегию с экспоненциальным backoff для обработки временных сбоев, автоматическое управление rate limiting при получении HTTP 429 ошибок, настройку таймаутов и user-agent заголовков для имитации реального браузера, а также адаптивное управление задержками в зависимости от ответов сервера. Данный компонент обеспечивает надежное и эффективное взаимодействие с внешним API.

\textbf{DataPersistence} отвечает за управление персистентностью данных в системе. Компонент обеспечивает атомарные операции записи для предотвращения потери данных при сбоях, загрузку уже обработанных данных для реализации инкрементального сбора, использование CSV формата с JSON для сложных полей (inputs, outputs транзакций), а также восстановление состояния системы при перезапуске. Надежная система персистентности критически важна для долгосрочных процессов сбора данных.

\textbf{BitcoinDataCollector} является основным оркестратором всей системы, координирующим работу всех компонентов. Данный компонент реализует инкрементальную обработку данных с отслеживанием прогресса, параллельное выполнение операций с использованием ThreadPoolExecutor, управление жизненным циклом всех процессов, а также координацию между различными компонентами системы. Оркестратор обеспечивает целостность и эффективность всего процесса сбора данных.

\textbf{Принципы проектирования архитектуры:}

\textbf{Инкрементальность} является ключевым принципом архитектуры, обеспечивающим возможность продолжения сбора данных с места остановки. Система отслеживает все обработанные адреса и транзакции, пропускает уже собранные данные для минимизации дублирования запросов, автоматически восстанавливается после сбоев, и обеспечивает минимальные потери данных при прерывании процесса. Данный подход критически важен для долгосрочных проектов сбора данных, где полная перезагрузка может занять значительное время.

\textbf{Батчевая обработка} оптимизирует производительность системы через группировку операций. Адреса обрабатываются батчами по 20 записей, транзакции - батчами по 100 записей, что обеспечивает периодическое сохранение промежуточных результатов и минимизирует количество I/O операций. Батчевый подход также снижает нагрузку на API и улучшает общую производительность системы.

\textbf{Параллелизм} обеспечивает эффективное использование ресурсов системы. ThreadPoolExecutor используется для параллельной обработки адресов с настраиваемым количеством воркеров (по умолчанию 5), транзакции обрабатываются последовательно для избежания дублирования, а синхронизация доступа к общим ресурсам предотвращает конфликты. Параллельная обработка значительно ускоряет сбор данных при соблюдении лимитов API.

\textbf{Устойчивость} обеспечивает надежность системы в условиях нестабильной сети и внешних API. Система реализует retry с экспоненциальным backoff для обработки временных сбоев, специальную обработку HTTP ошибок (429, 5xx), graceful degradation при критических сбоях, а также комплексное логирование и мониторинг состояния системы. Устойчивость критически важна для долгосрочных процессов сбора данных, где сбои неизбежны.

\subsubsection{Детальная методология сбора}

\textbf{Детальная методология сбора данных:}

Методология сбора данных представляет собой комплексный процесс, состоящий из четырех основных этапов, каждый из которых имеет свои специфические задачи и механизмы реализации. Процесс начинается с инициализации системы, которая включает загрузку уже обработанных адресов и транзакций из CSV файлов для обеспечения инкрементальности, создание HTTP сессии с настроенной retry стратегией для обеспечения надежности соединений, настройку параметров параллелизма и батчинга в соответствии с возможностями системы и ограничениями API, а также инициализацию системы логирования для мониторинга процесса и отладки.

Сбор адресов представляет собой ключевой этап процесса, который начинается с фильтрации новых адресов путем исключения уже обработанных записей из базы данных. Затем система выполняет параллельные API вызовы с использованием ThreadPoolExecutor для максимального использования ресурсов системы, при этом соблюдая ограничения API по количеству одновременных запросов. Результаты сохраняются батчами каждые 20 адресов для минимизации потерь данных при сбоях, а список обработанных адресов обновляется в реальном времени для обеспечения инкрементальности процесса.

Сбор транзакций является следующим этапом, который включает извлечение уникальных идентификаторов транзакций (txid) из всех собранных адресов для избежания дублирования данных. Транзакции обрабатываются последовательно для предотвращения конфликтов и дублирования запросов, при этом каждая транзакция обогащается детальной информацией о входах, выходах, размере, времени и других атрибутах. Результаты сохраняются батчами каждые 100 транзакций для оптимизации производительности и минимизации нагрузки на файловую систему.

Система персистентности обеспечивает надежное хранение данных через атомарные операции записи в CSV файлы, что предотвращает потерю данных при сбоях системы. Сложные поля, такие как inputs и outputs транзакций, сериализуются в JSON формат для сохранения структурированности данных. Система обеспечивает восстановление состояния при перезапуске, что позволяет продолжить процесс сбора с места остановки, а также создает резервные копии критически важных данных для обеспечения долгосрочной надежности.

\textbf{Конфигурация системы} включает следующие ключевые параметры: задержка между запросами составляет 1.0 секунду для соблюдения лимитов API, количество параллельных воркеров установлено в 5 для оптимального баланса производительности и нагрузки на API, размер батча для адресов составляет 20 записей для эффективной обработки, размер батча для транзакций равен 100 записям для оптимизации I/O операций, таймаут HTTP запросов установлен в 30 секунд для обработки медленных соединений, количество повторов при ошибках составляет 3 для обеспечения надежности, а коэффициент экспоненциального backoff равен 0.3 для оптимального управления задержками при повторных попытках.

\subsubsection{Технические аспекты реализации}

\textbf{Технические аспекты реализации системы:}

Система обработки ошибок представляет собой многоуровневую архитектуру, обеспечивающую надежность работы в условиях нестабильной сети и внешних API. HTTP ошибки обрабатываются через retry механизм с экспоненциальным backoff, который автоматически увеличивает задержки между повторными попытками для снижения нагрузки на сервер. Rate limiting обрабатывается через автоматическое увеличение задержки при получении HTTP 429 ошибок, что позволяет системе адаптироваться к ограничениям API в реальном времени. Сетевые ошибки логируются с подробной информацией для последующего анализа, при этом система продолжает обработку других запросов. Некорректные данные валидируются с использованием fallback значений для обеспечения целостности датасета, а система восстановления обеспечивает автоматическое продолжение процесса сбора с места остановки при перезапуске.

Производительность системы оптимизирована через комплексный подход к управлению ресурсами. Параллелизм ограничен 5 одновременными запросами к API для соблюдения лимитов провайдера и предотвращения блокировки. Батчинг минимизирует I/O операции через группировку записей, что снижает нагрузку на файловую систему и улучшает общую производительность. Кэширование реализовано через отслеживание обработанных данных, что исключает дублирование запросов и оптимизирует использование ресурсов. Система автоматически пропускает уже обработанные адреса и транзакции, что обеспечивает эффективность инкрементального сбора данных.

Rate Limiting управляется через адаптивные механизмы, которые автоматически корректируют параметры системы в зависимости от ответов API. Адаптивные задержки увеличиваются при получении 429 ошибок и постепенно уменьшаются при успешных запросах, что обеспечивает оптимальный баланс между скоростью сбора и соблюдением ограничений API. User-Agent ротация использует различные заголовки для имитации различных браузеров и обхода ограничений, основанных на идентификации клиента. Мониторинг отслеживает статус API в реальном времени и автоматически корректирует параметры системы для обеспечения стабильной работы. Приоритизация обеспечивает обработку критически важных данных в первую очередь, что минимизирует потери при сбоях системы.

\subsubsection{Методология обработки и структурирования данных}

Методология обработки и структурирования данных в рамках первого модуля НИРС направлена на подготовку сырых данных для последующего анализа и извлечения признаков. Данная методология включает процессы очистки, нормализации, валидации и структурирования собранных данных о Bitcoin-адресах и транзакциях.

\textbf{Очистка данных:}

Процесс очистки данных начинается с удаления некорректных записей и дубликатов из собранного датасета. Система фильтрует неполные транзакции с отсутствующими входными или выходными данными, что критически важно для обеспечения целостности анализа. Проверка валидности Bitcoin-адресов выполняется с использованием криптографических алгоритмов для исключения некорректных записей. Дополнительно удаляются транзакции с нулевыми суммами или некорректными значениями, которые могут исказить результаты анализа.

\textbf{Нормализация данных:}

Нормализация обеспечивает единообразие представления данных для последующей обработки. Данные приводятся к единому формату с стандартизацией типов данных для всех полей. Временные метки стандартизируются путем приведения к UTC и использованию единого формата для всех временных характеристик. Единицы измерения унифицируются с использованием сатоши для сумм и байтов для размеров транзакций. Адреса нормализуются к стандартному формату Base58 для обеспечения консистентности.

\textbf{Валидация данных:}

Система валидации обеспечивает проверку целостности и корректности обработанных данных. Выполняется верификация балансов и сумм транзакций для выявления аномалий в данных. Контролируется соответствие меток классов исходным данным для обеспечения качества разметки. Проверяется временная последовательность транзакций для выявления хронологических несоответствий. Дополнительно валидируется корректность связей между адресами и транзакциями.

\textbf{Структурирование данных:}

Финальный этап обработки включает организацию данных в структурированном формате для эффективного анализа. Данные организуются в табличном формате CSV с четкой схемой полей. Создаются связи между адресами и транзакциями для обеспечения целостности данных. Формируются индексы для быстрого поиска и доступа к данным. Данные группируются по категориям и временным периодам для облегчения последующего анализа.

\textbf{Контроль качества данных:}

Система контроля качества включает мониторинг полноты данных, проверку консистентности между различными источниками, валидацию статистических характеристик датасета, а также создание отчетов о качестве данных. Контроль качества критически важен для обеспечения надежности результатов последующего анализа и извлечения признаков.

В результате работы модуля сбора данных был создан структурированный датасет, содержащий файл addresses.csv с 8,810 Bitcoin-адресами с метками классов, файл transactions.csv с 292,820 транзакциями (объем 4.62 ГБ), метаданные с информацией о блоках и временными характеристиками, а также граф связей между адресами в транзакциях. Данный датасет готов для дальнейшей обработки и анализа в рамках второго модуля НИРС.

Для автоматизации процесса сбора данных был разработан Python-скрипт \texttt{bitcoin\_collector.py} \cite{python_handbook}, который обеспечивает параллельный сбор данных с использованием многопоточности, обработку ошибок и повторные попытки при сбоях, инкрементальное сохранение данных и контроль скорости запросов для соблюдения лимитов API. Скрипт использует библиотеку requests \cite{requests_library} для HTTP-запросов, стандартный формат CSV \cite{csv_standard} для хранения данных и JSON \cite{json_standard} для обмена данными с API, следуя практикам проектирования REST API \cite{api_design}. Полный исходный код системы сбора данных доступен в GitHub репозитории \cite{github_repo}.

\subsection{Выводы по результатам сбора данных}

\textbf{Основные достижения модуля сбора данных:}

1. \textbf{Масштаб собранных данных}: Успешно собрано 8,810 Bitcoin-адресов с полной историей транзакций, что составляет репрезентативную выборку для анализа различных типов кошельков в сети Bitcoin.

2. \textbf{Качество данных}: Использование датасета Гарвардского университета в качестве базового источника обеспечило высокое качество категоризации адресов, основанной на экспертной оценке.

3. \textbf{Техническая эффективность}: Разработанная система сбора данных показала высокую эффективность, собрав 292,820 транзакций объемом 4.62 ГБ с минимальными потерями данных благодаря системе обработки ошибок и повторных попыток.

\textbf{Выявленные особенности датасета:}

1. \textbf{Временной охват}: Данные охватывают период с 2009 по 2020 год, что позволяет анализировать эволюцию паттернов использования Bitcoin-адресов на протяжении более чем десятилетия.

2. \textbf{Разнообразие категорий}: Датасет включает 6 основных категорий кошельков (майнеры, биржи, сервисы, азартные игры, микшинг-сервисы, майнинг-пулы), что обеспечивает полноту анализа различных типов участников сети.

3. \textbf{Структурированность}: Данные организованы в табличном формате с четкими связями между адресами и транзакциями, что упрощает дальнейшую обработку и анализ.

\textbf{Практическая значимость:}

1. \textbf{Готовность к анализу}: Созданный датасет полностью готов для применения методов машинного обучения и статистического анализа без дополнительной предобработки.

2. \textbf{Масштабируемость}: Разработанная система сбора данных может быть легко адаптирована для сбора дополнительных данных или обновления существующего датасета.

3. \textbf{Воспроизводимость}: Все этапы сбора данных документированы и автоматизированы, что обеспечивает возможность воспроизведения результатов другими исследователями.
